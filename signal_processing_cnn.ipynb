{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cdb78-fb7f-42ea-b038-338cba8d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5405e-de40-4ac9-9588-62be9b2759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dir_path = '/content/drive/MyDrive/Project_3/'\n",
    "audio_classes = ['Normal', 'Wheezing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a07574-2cf3-41ea-bac1-116949789d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path= dir_path + 'Normal/BP30_N,N,P R M,18,F.wav'\n",
    "audio_data, sample_rate=librosa.load(audio_path)\n",
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049ee4f-5e23-4361-bce0-41b0dede0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f22fa-7f71-4985-a166-3e5e9489f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb3519-a275-47e9-9da0-9af7b82b270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_audio(audio, sr, target_length_sec):\n",
    "    current_length = len(audio) / sr\n",
    "    rate = current_length / target_length_sec\n",
    "    stretched = librosa.effects.time_stretch(audio, rate=rate)\n",
    "    return stretched\n",
    "\n",
    "# Usage\n",
    "audio, sr = librosa.load(audio_path)\n",
    "audio = time_stretch_audio(audio, sr, target_length_sec=15.0)\n",
    "mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b7893-1bf3-4629-93c0-c2ba0f2366fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features from audio waves\n",
    "\n",
    "Normal = list(Path(dir_path+audio_classes[0]).rglob('*.wav'))\n",
    "Wheezing = list(Path(dir_path+audio_classes[1]).rglob('*.wav'))\n",
    "len(Normal), len(Wheezing)\n",
    "\n",
    "x = np.zeros((105+129, 40, 646))\n",
    "y = np.zeros(105+129)\n",
    "\n",
    "for i, path in enumerate(Normal + Wheezing):\n",
    "    audio, sr = librosa.load(path)\n",
    "    audio = time_stretch_audio(audio, sr, target_length_sec=15.0)\n",
    "    feature = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    x[i] = feature\n",
    "    if i < len(Normal):\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3b457-6c79-4c68-bc4f-f39516447805",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tensor, y_tensor = torch.from_numpy(x).float(), torch.from_numpy(y).long()\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x_tensor, y_tensor, test_size=0.2)\n",
    "\n",
    "train_data = TensorDataset(x_tr, y_tr)\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd58de7-b252-4f4d-a506-b5207e50852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class ActGHFFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, s, t, m1, m2):\n",
    "\n",
    "        # Forward computation\n",
    "        num = 1 + m1 * t\n",
    "        den = 1 + m2 * t * torch.exp(-s/t)\n",
    "        output = num / den\n",
    "\n",
    "        # Save for backward pass\n",
    "        ctx.save_for_backward(t, m1, m2, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        t, m1, m2, output = ctx.saved_tensors\n",
    "\n",
    "        # Compute gradient using the provided formula\n",
    "        grad_s = (1/t) * output * (1 - (1/(1 + m1*t)) * output)\n",
    "\n",
    "        # Return gradients (None for fixed params t, m1, m2)\n",
    "        return grad_output * grad_s, None, None, None\n",
    "\n",
    "class ActGHF(nn.Module):\n",
    "    def __init__(self, t=0.5, m1=-1.001, m2=50):\n",
    "        super(ActGHF, self).__init__()\n",
    "        # Register as buffers since they're fixed parameters\n",
    "        self.register_buffer('t', torch.tensor(float(t)))\n",
    "        self.register_buffer('m1', torch.tensor(float(m1)))\n",
    "        self.register_buffer('m2', torch.tensor(float(m2)))\n",
    "\n",
    "    def forward(self, s):\n",
    "        return ActGHFFunction.apply(s, self.t, self.m1, self.m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e60cb-f551-4223-a1fc-ddd89ad4ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, model, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)  # Forward pass\n",
    "        self.test_accuracy(preds, y)  # Update accuracy metric\n",
    "        return preds\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "\n",
    "\n",
    "def create_trainer(model_name, max_epochs=5):\n",
    "    import logging\n",
    "    logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "    return pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        strategy=\"auto\",\n",
    "        precision=\"16-mixed\",\n",
    "        devices=-1,\n",
    "        max_epochs=max_epochs,\n",
    "        logger=pl.loggers.TensorBoardLogger('results/', name=model_name),\n",
    "        check_val_every_n_epoch=3,\n",
    "        callbacks=[\n",
    "            LearningRateMonitor(),\n",
    "            EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=4),\n",
    "            # Add this callback to save the best model\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor=\"val_acc\",        # Metric to monitor\n",
    "                mode=\"max\",               # Save when max accuracy\n",
    "                save_top_k=1,             # Save only the best model\n",
    "                filename=\"{epoch}-{val_acc:.4f}\",  # Include accuracy in filename\n",
    "                save_last=False,          # Don't save final epoch if not best\n",
    "                verbose=True              # Print when new best model is saved\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation_fn=nn.ReLU(), in_channels=40):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Convolutional network\n",
    "        self.sequential1 = nn.Sequential(\n",
    "            # Convolution 1\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=40),\n",
    "            nn.BatchNorm1d(16),\n",
    "            activation_fn,\n",
    "\n",
    "            # Convolution 2\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=8),\n",
    "            nn.BatchNorm1d(32),\n",
    "            activation_fn,\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            )\n",
    "\n",
    "        # Fully connected network\n",
    "        self.sequential2 = nn.Sequential(\n",
    "            nn.Linear(4800, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            activation_fn,\n",
    "            nn.Linear(128, 2),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.sequential2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e056e18-4893-4da5-b421-7a01ebf3d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {\n",
    "    'GHF': ActGHF(t=0.3),\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'Mish': nn.Mish(),\n",
    "    'Logistic': nn.Sigmoid(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'LReLU': nn.LeakyReLU()\n",
    "}\n",
    "for name, act in activation.items():\n",
    "    model = CNN(activation_fn=act)\n",
    "    print('Train with: ', name)\n",
    "    trainer = create_trainer(name, max_epochs=50)\n",
    "    classifier = Classifier(model, num_classes=2)\n",
    "    trainer.fit(classifier, train_loader,test_loader)\n",
    "    trainer.test(classifier, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1364683-7b3f-42ce-a4e2-61d6f7dd48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the checkpoint file\n",
    "import glob\n",
    "version = 0\n",
    "activation = {\n",
    "    'GHF': ActGHF(),\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'Mish': nn.Mish(),\n",
    "    'Logistic': nn.Sigmoid(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'LReLU': nn.LeakyReLU()\n",
    "}\n",
    "num_classes = 2\n",
    "for name, act in activation.items():\n",
    "    checkpoint_path = f\"results/{name}/version_{version}/checkpoints\"\n",
    "    ckp_file = glob.glob(f'{checkpoint_path}/*.ckpt')\n",
    "\n",
    "    # cnn_model = CNN(activation_fn=act)\n",
    "    model = CNN(activation_fn=act)\n",
    "    print('Accuracy for: ', name)\n",
    "    model = Classifier.load_from_checkpoint(ckp_file[0], model=model, num_classes=2)\n",
    "    results = trainer.test(model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
